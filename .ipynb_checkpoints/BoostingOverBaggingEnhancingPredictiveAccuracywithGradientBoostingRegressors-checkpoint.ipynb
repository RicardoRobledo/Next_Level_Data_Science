{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2328bcc-7cd7-4e68-aef9-346a40d0608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (1 Tree): Mean CV R^2 = 0.7663\n",
      "Bagging Regressor (100 Decision Trees): Mean CV R^2 = 0.8957\n",
      "Bagging Regressor (200 Decision Trees): Mean CV R^2 = 0.897\n",
      "Random Forest (Default of 100 Trees): Mean CV R^2 = 0.8954\n",
      "Random Forest (200 Trees): Mean CV R^2 = 0.8969\n",
      "Gradient Boosting Regressor (Default of 100 Trees): Mean CV R^2 = 0.9027\n",
      "Gradient Boosting Regressor (200 Trees): Mean CV R^2 = 0.9061\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for preprocessing and modeling\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor, BaggingRegressor, RandomForestRegressor\n",
    "\n",
    "# Load the dataset\n",
    "Ames = pd.read_csv(\"Ames.csv\")\n",
    "\n",
    "# Adjust data types for categorical variables\n",
    "for col in [\"MSSubClass\", \"YrSold\", \"MoSold\"]:\n",
    "    Ames[col] = Ames[col].astype(\"object\")\n",
    "\n",
    "# Exclude \"PID\" and \"SalePrice\" from features and handle the \"Electrical\" column\n",
    "numeric_features = Ames.select_dtypes(include=[\"int64\", \"float64\"]) \\\n",
    "    .drop(columns=[\"PID\", \"SalePrice\"]).columns\n",
    "categorical_features = Ames.select_dtypes(include=[\"object\"]).columns \\\n",
    "    .difference([\"Electrical\"])\n",
    "electrical_feature = [\"Electrical\"]\n",
    "\n",
    "# Manually specify the categories for ordinal encoding according to the data dictionary\n",
    "ordinal_order = {\n",
    "    # Electrical system\n",
    "    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n",
    "    # General shape of property\n",
    "    \"LotShape\": [\"IR3\", \"IR2\", \"IR1\", \"Reg\"],\n",
    "    # Type of utilities available\n",
    "    \"Utilities\": [\"ELO\", \"NoSeWa\", \"NoSewr\", \"AllPub\"],\n",
    "    # Slope of property\n",
    "    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n",
    "    # Evaluates the quality of the material on the exterior\n",
    "    \"ExterQual\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    # Evaluates the present condition of the material on the exterior\n",
    "    \"ExterCond\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    # Height of the basement\n",
    "    \"BsmtQual\": [\"None\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    # General condition of the basement\n",
    "    \"BsmtCond\": [\"None\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    # Walkout or garden level basement walls\n",
    "    \"BsmtExposure\": [\"None\", \"No\", \"Mn\", \"Av\", \"Gd\"],\n",
    "    # Quality of basement finished area\n",
    "    \"BsmtFinType1\": [\"None\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    # Quality of second basement finished area\n",
    "    \"BsmtFinType2\": [\"None\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    # Heating quality and condition\n",
    "    \"HeatingQC\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    # Kitchen quality\n",
    "    \"KitchenQual\": [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    # Home functionality\n",
    "    \"Functional\": [\"Sal\", \"Sev\", \"Maj2\", \"Maj1\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n",
    "    # Fireplace quality\n",
    "    \"FireplaceQu\": [\"None\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    # Interior finish of the garage\n",
    "    \"GarageFinish\": [\"None\", \"Unf\", \"RFn\", \"Fin\"],\n",
    "    # Garage quality\n",
    "    \"GarageQual\": [\"None\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    # Garage condition\n",
    "    \"GarageCond\": [\"None\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    # Paved driveway\n",
    "    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n",
    "    # Pool quality\n",
    "    \"PoolQC\": [\"None\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    # Fence quality\n",
    "    \"Fence\": [\"None\", \"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"]\n",
    "}\n",
    "\n",
    "# Extract list of ALL ordinal features from dictionary\n",
    "ordinal_features = list(ordinal_order.keys())\n",
    "# List of ordinal features except Electrical\n",
    "ordinal_except_electrical = [feat for feat in ordinal_features if feat != \"Electrical\"]\n",
    "\n",
    "# Define transformations for various feature types\n",
    "electrical_transformer = Pipeline(steps=[\n",
    "    (\"impute_electrical\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ordinal_electrical\", OrdinalEncoder(categories=[ordinal_order[\"Electrical\"]]))\n",
    "])\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"impute_mean\", SimpleImputer(strategy=\"mean\"))\n",
    "])\n",
    "\n",
    "# Updated categorical imputer using SimpleImputer\n",
    "categorical_imputer = SimpleImputer(strategy=\"constant\", fill_value=\"None\")\n",
    "\n",
    "ordinal_transformer = Pipeline([\n",
    "    (\"impute_ordinal\", categorical_imputer),\n",
    "    (\"ordinal\", OrdinalEncoder(categories=[ordinal_order[feat]\n",
    "                                           for feat in ordinal_features\n",
    "                                           if feat in ordinal_except_electrical]))\n",
    "])\n",
    "\n",
    "nominal_features = [feat for feat in categorical_features if feat not in ordinal_features]\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"impute_nominal\", categorical_imputer),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combined preprocessor for numeric, ordinal, nominal, and specific electrical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"electrical\", electrical_transformer, [\"Electrical\"]),\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"ordinal\", ordinal_transformer, ordinal_except_electrical),\n",
    "        (\"nominal\", categorical_transformer, nominal_features)\n",
    "    ])\n",
    "\n",
    "# Define model pipelines including Gradient Boosting Regressor\n",
    "models = {\n",
    "    \"Decision Tree (1 Tree)\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Bagging Regressor (100 Decision Trees)\": BaggingRegressor(\n",
    "        estimator=DecisionTreeRegressor(random_state=42),\n",
    "        n_estimators=100, random_state=42),\n",
    "    \"Bagging Regressor (200 Decision Trees)\": BaggingRegressor(\n",
    "        estimator=DecisionTreeRegressor(random_state=42),\n",
    "        n_estimators=200, random_state=42),\n",
    "    \"Random Forest (Default of 100 Trees)\": RandomForestRegressor(random_state=42),\n",
    "    \"Random Forest (200 Trees)\": RandomForestRegressor(n_estimators=200, random_state=42),\n",
    "    \"Gradient Boosting Regressor (Default of 100 Trees)\": GradientBoostingRegressor(random_state=42),\n",
    "    \"Gradient Boosting Regressor (200 Trees)\": GradientBoostingRegressor(n_estimators=200, random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluate models using cross-validation and print results\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model_pipeline = Pipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", model)\n",
    "    ])\n",
    "    scores = cross_val_score(model_pipeline,\n",
    "                             Ames.drop(columns=\"SalePrice\"),\n",
    "                             Ames[\"SalePrice\"],\n",
    "                             cv=5)\n",
    "    results[name] = round(scores.mean(), 4)\n",
    "    print(f\"{name}: Mean CV R^2 = {results[name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff7c9b7-323a-4120-934b-0bdb01d5e437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    }
   ],
   "source": [
    "# Experiment with GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    \"regressor__learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "# Setup the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    model_pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"r2\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV to the data\n",
    "grid_search.fit(Ames.drop(columns=\"SalePrice\"), Ames[\"SalePrice\"])\n",
    "\n",
    "# Best parameters and best score from Grid Search\n",
    "print(\"Best parameters (Grid Search):\", grid_search.best_params_)\n",
    "print(\"Best score (Grid Search):\", round(grid_search.best_score_, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71113ef8-12ce-4b7d-af81-a3c3c05b275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Parameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    # Uniform distribution between 0.001 and 0.3\n",
    "    \"regressor__learning_rate\": uniform(0.001, 0.299)\n",
    "}\n",
    "\n",
    "# Setup the RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    model_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring=\"r2\",\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "random_search.fit(Ames.drop(columns=\"SalePrice\"), Ames[\"SalePrice\"])\n",
    "\n",
    "# Best parameters and best score from Random Search\n",
    "print(\"Best parameters (Random Search):\", random_search.best_params_)\n",
    "print(\"Best score (Random Search):\", round(random_search.best_score_, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a334c818-2a05-4601-90d9-2b1276a60e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"preprocessor\" is already set up as your preprocessing pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    \"regressor__learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "    \"regressor__n_estimators\": [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "# Setup the GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    model_pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"r2\",\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV to the data\n",
    "grid_search.fit(Ames.drop(columns=\"SalePrice\"), Ames[\"SalePrice\"])\n",
    "\n",
    "# Best parameters and best score from Grid Search\n",
    "print(\"Best parameters (Grid Search):\", grid_search.best_params_)\n",
    "print(\"Best score (Grid Search):\", round(grid_search.best_score_, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4986d260-94be-45ad-b13c-6698ad90e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Parameter distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    # Uniform distribution between 0.001 and 0.3\n",
    "    \"regressor__learning_rate\": uniform(0.001, 0.299),\n",
    "    # Uniform distribution of integers from 100 to 500\n",
    "    \"regressor__n_estimators\": randint(100, 501)\n",
    "}\n",
    "\n",
    "# Setup the RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    model_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring=\"r2\",\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the RandomizedSearchCV to the data\n",
    "random_search.fit(Ames.drop(columns=\"SalePrice\"), Ames[\"SalePrice\"])\n",
    "\n",
    "# Best parameters and best score from Random Search\n",
    "print(\"Best parameters (Random Search):\", random_search.best_params_)\n",
    "print(\"Best score (Random Search):\", round(random_search.best_score_, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14368a-f6c5-4809-8b83-66eb6afb8767",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", GradientBoostingRegressor(\n",
    "        n_estimators=287,\n",
    "        learning_rate=0.12055843054286139,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Using the full dataset X, y\n",
    "X = Ames.drop(columns=\"SalePrice\")\n",
    "y = Ames[\"SalePrice\"]\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(model_pipeline, X, y, cv=5, scoring=\"r2\")\n",
    "\n",
    "# Output the mean cross-validated score of tuned model\n",
    "print(\n",
    "    \"Performance of gradient boosting regressor with tuned parameters:\",\n",
    "    round(cv_scores.mean(), 4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51908f86-35f8-498f-b5d3-c9f20834bb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
